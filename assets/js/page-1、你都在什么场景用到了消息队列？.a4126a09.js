(window.webpackJsonp=window.webpackJsonp||[]).push([[42],{486:function(_,v,e){_.exports=e.p+"assets/img/16ef388763c25c62.2deb563b.jpg"},673:function(_,v,e){"use strict";e.r(v);var o=e(1),t=Object(o.a)({},(function(){var _=this,v=_.$createElement,o=_._self._c||v;return o("ContentSlotsDistributor",{attrs:{"slot-key":_.$parent.slotKey}},[o("h4",{attrs:{id:"_1、你都在什么场景用到了消息队列"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#_1、你都在什么场景用到了消息队列"}},[_._v("#")]),_._v(" 1、你都在什么场景用到了消息队列？")]),_._v(" "),o("p",[o("strong",[_._v("异步、削峰、解耦")])]),_._v(" "),o("p",[_._v("异步：省时间。")]),_._v(" "),o("p",[_._v("解耦：省代码。")]),_._v(" "),o("h5",{attrs:{id:"为什么不用线程池去做"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#为什么不用线程池去做"}},[_._v("#")]),_._v(" 为什么不用线程池去做？")]),_._v(" "),o("p",[_._v("因为要不断的改业务代码，然后还要重新发版本，麻烦。")]),_._v(" "),o("p",[_._v("削峰：系统的请求过多，服务器处理能力不够，可能会打挂服务器。解决办法可以是把请求放到队列里面，然后至于每秒消费多少请求，就看自己的服务器处理能力。")]),_._v(" "),o("h4",{attrs:{id:"_2、如何解决重复消费问题"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#_2、如何解决重复消费问题"}},[_._v("#")]),_._v(" 2、如何解决重复消费问题？")]),_._v(" "),o("p",[_._v("问题描述：现在有几个不同的系统监听着同一个系统，当其中一个业务出了异常，会有重试机制，当重发消息之后，其他的系统还是会接收到这个消息。真实情况的重试是很正常的，譬如服务的网络抖动，代码的 bug，还有数据问题等可能需要重发消息。")]),_._v(" "),o("h5",{attrs:{id:"怎么解决重复消费"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#怎么解决重复消费"}},[_._v("#")]),_._v(" 怎么解决重复消费？")]),_._v(" "),o("p",[_._v("幂等：通俗讲就是一个同样的参数调用这个接口，调用多少次结果都是一样。")]),_._v(" "),o("h5",{attrs:{id:"怎么保证幂等"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#怎么保证幂等"}},[_._v("#")]),_._v(" 怎么保证幂等？")]),_._v(" "),o("p",[_._v("一般会分场景去考虑，看是强校验还是弱校验。比如支付相关的场景那很关键，需要强校验，别的不是很重要的就做弱校验。")]),_._v(" "),o("p",[o("strong",[_._v("强校验")]),_._v("：比如你监听到用户支付成功的消息，你监听到了去加GMV是不是要调用加钱的接口，那加钱接口下面再调用一个加流水的接口，"),o("strong",[_._v("两个放在一个事务，成功一起成功失败一起失败")]),_._v("。")]),_._v(" "),o("p",[_._v("每次消息过来都要拿着"),o("strong",[_._v("订单号+业务场景这样的唯一标识")]),_._v("（比如天猫双十一活动）去流水表查，看看有没有这条流水，有就直接return不要走下面的流程了，没有就执行后面的逻辑。")]),_._v(" "),o("p",[_._v("之所以用"),o("strong",[_._v("流水表")]),_._v("，是因为涉及到金钱这样的活动，有啥问题后面也可以去流水表"),o("strong",[_._v("对账")]),_._v("，还有就是帮助开发人员定位问题。")]),_._v(" "),o("p",[o("strong",[_._v("弱校验")]),_._v("：这个简单，一些不重要的场景，比如给谁发短信啥的，我就把这个id+场景唯一标识作为"),o("strong",[_._v("Redis")]),_._v("的key，放到缓存里面。失效时间看你场景，"),o("strong",[_._v("一定时间内")]),_._v("的这个消息就去Redis判断。用KV就算消息丢了可能这样的场景也没关系，反正丢条"),o("strong",[_._v("无关痛痒")]),_._v("的通知短信。")]),_._v(" "),o("h4",{attrs:{id:"_3、如何解决消息的顺序消费问题"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#_3、如何解决消息的顺序消费问题"}},[_._v("#")]),_._v(" 3、如何解决消息的顺序消费问题？")]),_._v(" "),o("p",[_._v("问题描述：一般都是"),o("strong",[_._v("同个业务场景下不同几个操作的消息同时过去")]),_._v("，本身顺序是对的，但是你发出去的时候同时发出去了，消费的时候却乱掉了，这样就有问题了。")]),_._v(" "),o("h5",{attrs:{id:"如何解决"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#如何解决"}},[_._v("#")]),_._v(" 如何解决？")]),_._v(" "),o("p",[o("strong",[_._v("RocketMQ")]),_._v("提供了"),o("strong",[_._v("MessageQueueSelector")]),_._v("队列选择机制，他有三种实现，使用 "),o("strong",[_._v("Hash取模法")]),_._v(" 来保证同一个订单在同一个队列中就行了。"),o("strong",[_._v("RocketMQ")]),_._v("的topic内的队列机制,可以保证存储满足"),o("strong",[_._v("FIFO")]),_._v("（First Input First Output 简单说就是指先进先出）,剩下的只需要消费者顺序消费即可。至于怎么保证消费者顺序消费，使用同步发送，只有前面的消费发送成功，再发送后面的。")]),_._v(" "),o("h4",{attrs:{id:"_4、如何解决分布式事务问题"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#_4、如何解决分布式事务问题"}},[_._v("#")]),_._v(" 4、如何解决分布式事务问题？")]),_._v(" "),o("p",[_._v("概念：不同是服务要么同时成功或者失败。")]),_._v(" "),o("p",[_._v("讲一个两阶段提交。")]),_._v(" "),o("p",[_._v("// seata 分布式事务原理")]),_._v(" "),o("h4",{attrs:{id:"_5、如何解决消息堆积问题"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#_5、如何解决消息堆积问题"}},[_._v("#")]),_._v(" 5、如何解决消息堆积问题")]),_._v(" "),o("p",[_._v("产生消息堆积的根源其实就只有两个——生产者生产太快或者消费者消费太慢。")]),_._v(" "),o("p",[_._v("我们可以从多个角度去思考解决这个问题，当流量到峰值的时候是因为生产者生产太快，我们可以使用一些 "),o("strong",[_._v("限流降级")]),_._v(" 的方法，当然你也可以增加多个消费者实例去水平扩展增加消费能力来匹配生产的激增。如果消费者消费过慢的话，我们可以先检查 "),o("strong",[_._v("是否是消费者出现了大量的消费错误")]),_._v(" ，或者打印一下日志查看是否是哪一个线程卡死，出现了锁资源不释放等等的问题")]),_._v(" "),o("h4",{attrs:{id:"_6、rocketmq-组成"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#_6、rocketmq-组成"}},[_._v("#")]),_._v(" 6、RocketMQ 组成")]),_._v(" "),o("img",{staticStyle:{zoom:"50%"},attrs:{src:"images/16ef38687488a5a4.jpg",alt:"img"}}),_._v(" "),o("ul",[o("li",[o("code",[_._v("Broker")]),_._v("： 主要负责消息的存储、投递和查询以及服务高可用保证。说白了就是消息队列服务器嘛，生产者生产消息到 "),o("code",[_._v("Broker")]),_._v(" ，消费者从 "),o("code",[_._v("Broker")]),_._v(" 拉取消息并消费。")])]),_._v(" "),o("p",[_._v("这里，我还得普及一下关于 "),o("code",[_._v("Broker")]),_._v(" 、"),o("code",[_._v("Topic")]),_._v(" 和 队列的关系。上面我讲解了 "),o("code",[_._v("Topic")]),_._v(" 和队列的关系——一个 "),o("code",[_._v("Topic")]),_._v(" 中存在多个队列，那么这个 "),o("code",[_._v("Topic")]),_._v(" 和队列存放在哪呢？")]),_._v(" "),o("p",[o("strong",[_._v("一个 "),o("code",[_._v("Topic")]),_._v(" 分布在多个 "),o("code",[_._v("Broker")]),_._v("上，一个 "),o("code",[_._v("Broker")]),_._v(" 可以配置多个 "),o("code",[_._v("Topic")]),_._v(" ，它们是多对多的关系")]),_._v("。")]),_._v(" "),o("p",[_._v("如果某个 "),o("code",[_._v("Topic")]),_._v(" 消息量很大，应该给它多配置几个队列(上文中提到了提高并发能力)，并且 "),o("strong",[_._v("尽量多分布在不同 "),o("code",[_._v("Broker")]),_._v(" 上，以减轻某个 "),o("code",[_._v("Broker")]),_._v(" 的压力")]),_._v(" 。")]),_._v(" "),o("ul",[o("li",[o("code",[_._v("NameServer")]),_._v("： 不知道你们有没有接触过 "),o("code",[_._v("ZooKeeper")]),_._v(" 和 "),o("code",[_._v("Spring Cloud")]),_._v(" 中的 "),o("code",[_._v("Eureka")]),_._v(" ，它其实也是一个 "),o("strong",[_._v("注册中心")]),_._v(" ，主要提供两个功能："),o("strong",[_._v("Broker管理")]),_._v(" 和 "),o("strong",[_._v("路由信息管理")]),_._v(" 。说白了就是 "),o("code",[_._v("Broker")]),_._v(" 会将自己的信息注册到 "),o("code",[_._v("NameServer")]),_._v(" 中，此时 "),o("code",[_._v("NameServer")]),_._v(" 就存放了很多 "),o("code",[_._v("Broker")]),_._v(" 的信息(Broker的路由表)，消费者和生产者就从 "),o("code",[_._v("NameServer")]),_._v(" 中获取路由表然后照着路由表的信息和对应的 "),o("code",[_._v("Broker")]),_._v(" 进行通信(生产者和消费者定期会向 "),o("code",[_._v("NameServer")]),_._v(" 去查询相关的 "),o("code",[_._v("Broker")]),_._v(" 的信息)。")]),_._v(" "),o("li",[o("code",[_._v("Producer")]),_._v("： 消息发布的角色，支持分布式集群方式部署。说白了就是生产者。")]),_._v(" "),o("li",[o("code",[_._v("Consumer")]),_._v("： 消息消费的角色，支持分布式集群方式部署。支持以push推，pull拉两种模式对消息进行消费。同时也支持集群方式和广播方式的消费，它提供实时消息订阅机制。说白了就是消费者。")])]),_._v(" "),o("h4",{attrs:{id:"_7、rocketmq-的刷盘机制-这部分不是很理解-下次重点看这里。"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#_7、rocketmq-的刷盘机制-这部分不是很理解-下次重点看这里。"}},[_._v("#")]),_._v(" 7、RocketMQ 的刷盘机制 ？？ 这部分不是很理解，下次重点看这里。")]),_._v(" "),o("h5",{attrs:{id:"同步刷盘和异步刷盘"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#同步刷盘和异步刷盘"}},[_._v("#")]),_._v(" 同步刷盘和异步刷盘")]),_._v(" "),o("img",{staticStyle:{zoom:"50%"},attrs:{src:"images/16ef387fba311cda.jpg",alt:"img"}}),_._v(" "),o("p",[_._v("如上图所示，在同步刷盘中需要等待一个刷盘成功的 "),o("code",[_._v("ACK")]),_._v(" ，同步刷盘对 "),o("code",[_._v("MQ")]),_._v(" 消息可靠性来说是一种不错的保障，但是 "),o("strong",[_._v("性能上会有较大影响")]),_._v(" ，一般地适用于金融等特定业务场景。")]),_._v(" "),o("p",[_._v("而异步刷盘往往是开启一个线程去异步地执行刷盘操作。消息刷盘采用后台异步线程提交的方式进行， "),o("strong",[_._v("降低了读写延迟")]),_._v(" ，提高了 "),o("code",[_._v("MQ")]),_._v(" 的性能和吞吐量，一般适用于如发验证码等对于消息保证要求不太高的业务场景。")]),_._v(" "),o("p",[_._v("一般地，"),o("strong",[_._v("异步刷盘只有在 "),o("code",[_._v("Broker")]),_._v(" 意外宕机的时候会丢失部分数据")]),_._v("，你可以设置 "),o("code",[_._v("Broker")]),_._v(" 的参数 "),o("code",[_._v("FlushDiskType")]),_._v(" 来调整你的刷盘策略(ASYNC_FLUSH 或者 SYNC_FLUSH)。")]),_._v(" "),o("h5",{attrs:{id:"同步复制和异步复制"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#同步复制和异步复制"}},[_._v("#")]),_._v(" 同步复制和异步复制")]),_._v(" "),o("p",[_._v("上面的同步刷盘和异步刷盘是在单个结点层面的，而同步复制和异步复制主要是指的 "),o("code",[_._v("Borker")]),_._v(" 主从模式下，主节点返回消息给客户端的时候是否需要同步从节点。")]),_._v(" "),o("ul",[o("li",[_._v("同步复制： 也叫 “同步双写”，也就是说，"),o("strong",[_._v("只有消息同步双写到主从节点上时才返回写入成功")]),_._v(" 。")]),_._v(" "),o("li",[_._v("异步复制： "),o("strong",[_._v("消息写入主节点之后就直接返回写入成功")]),_._v(" 。")])]),_._v(" "),o("h4",{attrs:{id:"_8、存储机制"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#_8、存储机制"}},[_._v("#")]),_._v(" 8、存储机制")]),_._v(" "),o("p",[_._v("三大角色——"),o("code",[_._v("CommitLog")]),_._v(" 、"),o("code",[_._v("ConsumeQueue")]),_._v(" 和 "),o("code",[_._v("IndexFile")])]),_._v(" "),o("ul",[o("li",[o("code",[_._v("CommitLog")]),_._v("： "),o("strong",[_._v("消息主体以及元数据的存储主体")]),_._v("，存储 "),o("code",[_._v("Producer")]),_._v(" 端写入的消息主体内容,消息内容不是定长的。单个文件大小默认1G ，文件名长度为20位，左边补零，剩余为起始偏移量，比如00000000000000000000代表了第一个文件，起始偏移量为0，文件大小为1G=1073741824；当第一个文件写满了，第二个文件为00000000001073741824，起始偏移量为1073741824，以此类推。消息主要是"),o("strong",[_._v("顺序写入日志文件")]),_._v("，当文件满了，写入下一个文件。")]),_._v(" "),o("li",[o("code",[_._v("ConsumeQueue")]),_._v("： 消息消费队列，"),o("strong",[_._v("引入的目的主要是提高消息消费的性能")]),_._v("(我们再前面也讲了)，由于"),o("code",[_._v("RocketMQ")]),_._v(" 是基于主题 "),o("code",[_._v("Topic")]),_._v(" 的订阅模式，消息消费是针对主题进行的，如果要遍历 "),o("code",[_._v("commitlog")]),_._v(" 文件中根据 "),o("code",[_._v("Topic")]),_._v(" 检索消息是非常低效的。"),o("code",[_._v("Consumer")]),_._v(" 即可根据 "),o("code",[_._v("ConsumeQueue")]),_._v(" 来查找待消费的消息。其中，"),o("code",[_._v("ConsumeQueue")]),_._v("（逻辑消费队列）"),o("strong",[_._v("作为消费消息的索引")]),_._v("，保存了指定 "),o("code",[_._v("Topic")]),_._v(" 下的队列消息在 "),o("code",[_._v("CommitLog")]),_._v(" 中的"),o("strong",[_._v("起始物理偏移量 "),o("code",[_._v("offset")]),_._v(" *"),o("em",[_._v("，消息大小 "),o("code",[_._v("size")]),_._v(" 和消息 "),o("code",[_._v("Tag")]),_._v(" 的 "),o("code",[_._v("HashCode")]),_._v(" 值。*")]),o("code",[_._v("consumequeue")]),_._v(" 文件可以看成是基于 "),o("code",[_._v("topic")]),_._v(" 的 "),o("code",[_._v("commitlog")]),_._v(" 索引文件")]),_._v("，故 "),o("code",[_._v("consumequeue")]),_._v(" 文件夹的组织方式如下：topic/queue/file三层组织结构，具体存储路径为：$HOME/store/consumequeue/{topic}/{queueId}/{fileName}。同样 "),o("code",[_._v("consumequeue")]),_._v(" 文件采取定长设计，每一个条目共20个字节，分别为8字节的 "),o("code",[_._v("commitlog")]),_._v(" 物理偏移量、4字节的消息长度、8字节tag "),o("code",[_._v("hashcode")]),_._v("，单个文件由30W个条目组成，可以像数组一样随机访问每一个条目，每个 "),o("code",[_._v("ConsumeQueue")]),_._v("文件大小约5.72M；")]),_._v(" "),o("li",[o("code",[_._v("IndexFile")]),_._v("： "),o("code",[_._v("IndexFile")]),_._v("（索引文件）提供了一种可以通过key或时间区间来查询消息的方法。这里只做科普不做详细介绍。、")])]),_._v(" "),o("p",[o("img",{attrs:{src:e(486),alt:"img",loading:"lazy"}})]),_._v(" "),o("p",[_._v("首先，在最上面的那一块就是我刚刚讲的你现在可以直接 "),o("strong",[_._v("把 "),o("code",[_._v("ConsumerQueue")]),_._v(" 理解为 "),o("code",[_._v("Queue")])]),_._v("。")]),_._v(" "),o("p",[_._v("在图中最左边说明了红色方块代表被写入的消息，虚线方块代表等待被写入的。左边的生产者发送消息会指定 "),o("code",[_._v("Topic")]),_._v(" 、"),o("code",[_._v("QueueId")]),_._v(" 和具体消息内容，而在 "),o("code",[_._v("Broker")]),_._v(" 中管你是哪门子消息，他直接 "),o("strong",[_._v("全部顺序存储到了 CommitLog")]),_._v("。而根据生产者指定的 "),o("code",[_._v("Topic")]),_._v(" 和 "),o("code",[_._v("QueueId")]),_._v(" 将这条消息本身在 "),o("code",[_._v("CommitLog")]),_._v(" 的偏移(offset)，消息本身大小，和tag的hash值存入对应的 "),o("code",[_._v("ConsumeQueue")]),_._v(" 索引文件中。而在每个队列中都保存了 "),o("code",[_._v("ConsumeOffset")]),_._v(" 即每个消费者组的消费位置(我在架构那里提到了，忘了的同学可以回去看一下)，而消费者拉取消息进行消费的时候只需要根据 "),o("code",[_._v("ConsumeOffset")]),_._v(" 获取下一个未被消费的消息就行了。")]),_._v(" "),o("h4",{attrs:{id:"stream-mq"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#stream-mq"}},[_._v("#")]),_._v(" Stream-MQ")]),_._v(" "),o("p",[_._v("1：配置文件通道命名和@input output一致，否则默认用注解的名字作为交换机名称。\n注意：输入通道和输出通道必须是同一个交换机才可通信")]),_._v(" "),o("p",[_._v("2：分组。每个消费者实例都会产生一个队列（几个消费者实例就有几个队列），当生产者发出某条消息，多个消费者都会收到，会出现重复消费问题。")]),_._v(" "),o("p",[_._v("分组可解决重复消费和持久化问题。一般用服务名称分组。\nExl：排他队列。跟随应用的启动停止而产生或消失。但是配置了group下次产生的时候还会收到之前未消费的消息。")]),_._v(" "),o("p",[_._v("3：分区。通过消费组的设置，虽然能保证同一消息只被一个消费者进行接收和处理，但是对于特殊业务情况，除了要保证单一实例消费之外，还希望那些具备相同特征的消息都能被同一个实例消费。有playload和header两种区分表达式")]),_._v(" "),o("p",[_._v("4：每个virtualhost 之间是隔离的，exchang不能互通。譬如生产环境和开发环境的，如果virtualhost相同，则两个环境都会收到消息")]),_._v(" "),o("p",[_._v("坑：\n1、如果只做生产者就不要指定 log input ，因为指定了这个，应用就会认为这个生产者服务也会消费消息，即没有@StreamListener。")]),_._v(" "),o("p",[_._v("2、注意消费者的配置和生产者的配置，是在各自的配置文件。但是exchang必须相同，不然不同的交换机无法通信。")]),_._v(" "),o("p",[_._v("3、队列下面会有多个消费者，多个实例分组以后，就会使用同一个队列（不分组就每个实例作为一个消费者产生一个队列，随服务关闭队列消失），但是如果想要这个队列中一类数据给同一个实例消费者，就需要分区。\n注意：分组之后消费者订阅过的都会收到消息")]),_._v(" "),o("p",[_._v("4、一个消费者在一个地方接受不同的生产者，可以enablebing 多个配置的通道")]),_._v(" "),o("p",[_._v("记录：\n1、\n输入流必须关闭流，否则数据还在内存，无法操作。譬如删除等。")])])}),[],!1,null,null,null);v.default=t.exports}}]);